---
title: "getting_data"
author: "olivier"
date: "3/18/2022"
output: html_document
---

The goal is to get all tracks and train stations off the [Amtrack network](https://en.wikipedia.org/wiki/List_of_Amtrak_routes) and the first step is getting data.

## Amtrack!

### Relations with network="Amtrack"

The First step is collecting data about Amtrack. I went with a query that get all [relations](https://wiki.openstreetmap.org/wiki/Relation). A csv file with the relation id and name but without coordinates was enough because at first we just want to pinpoint the relation that we need without downloading too much from the server. 

I have tuned the request in overpass turbo then used cURL. 

```{bash}
curl --globoff -o relation_amtrack.csv "http://overpass-api.de/api/interpreter?data=[out:csv(::type,::id,name)];rel[network="Amtrak"];out;"
```

I moved the csv in the `data/` repertory.

### Cleaning the csv

```{r}
relations_amtrack <- read.csv("../Data/relation_amtrack.csv", sep = "\t")
# we can drop relation and clean names
names(relations_amtrack) <- c("rel", "id", "name")
relations_amtrack <- relations_amtrack[, c("id", "name")]      
```

We just need the one with `=` in their name: "Amtrak Wolverine: Pontiac => Chicago"

```{r}
relations_amtrack <- relations_amtrack[grep(pattern = "=", relations_amtrack$name),]
```

Better! But we are still facing some trouble:

- we have potential duplicates: see `Amtrak Keystone Service: Harrisburg => Philadelphia` 

- we have two way: see `Seattle => Chicago` and `Chicago => Seattle`

We need to understand why we have duplicates.

### Identify one track that get all the informations  

Let see how many distinct name we get:

```{r}
unique_track <-  aggregate(data = relations_amtrack,
          id ~ name,
          FUN = function(x) length(unique(x)))

unique_track[order(unique_track$id, decreasing = TRUE),]

sum( unique_track$id > 1 ) # number of track that have more than one relation 
```

Start with one: 

```{r}
relations_amtrack[relations_amtrack$name =="Amtrak Keystone Service: Harrisburg => Philadelphia",]
```

For each relation we will construct a query that just ask the number of elements linked to that relations. This creates a bunch of files but I failed to understand how the statistical count works in overpass APi. 

```{r}

list_double <- relations_amtrack$id[relations_amtrack$name =="Amtrak Keystone Service: Harrisburg => Philadelphia"]

my_path <- "../Data/temp/"

for (i in 1:length(list_double)) {
    writeLines(paste0("[out:csv(::count)];relation(",list_double[i], ");>;out count;"), 
                         paste0(my_path, "query.osm"))
    # besoin de wget
    download.file("https://overpass-api.de/api/interpreter", method = "wget",
                  destfile = paste0(my_path, list_double[i], ".osm") ,
                  extra = paste0("--post-file=",
                  my_path,
                  "query.osm"))
}
```

I used this [web](https://overpass-api.de/command_line.html) page as a reference. 

```{r}
list_count <- list.files(path = "../Data/temp/")
list_count <- list_count[grep(pattern = "^[ 0-9]", list_count )]

my_path <- "../Data/temp/" 
nb_nodes <- vector(length = length(list_count))

for (i in 1:length(list_count)) {
    nb_nodes[i] = scan(paste0(my_path,list_count[i]), 
                        skip = 1, 
                        quiet = TRUE)
    print(nb_nodes[i])
}
    
list_count[which.max(nb_nodes)]    

```

Finally I can get the relation with the greatest number of elements.

### Getting all the duplicates

```{r}
relations_amtrack <- merge(relations_amtrack, unique_track, 
                           by.x = "name",
                           by.y = "name")
names(relations_amtrack) <- c("name", "id", "nb_lines")

multiple_tracks <- relations_amtrack[relations_amtrack$nb_lines > 1,]

multiple_tracks$same_lines <- as.numeric(as.factor(multiple_tracks$name))
```

Looping/apply each lines/duplicates:

```{r}

loop_over <- unique(multiple_tracks$same_lines)
my_path <- "../Data/temp/" 



for (i in loop_over) {
        temporary_table = multiple_tracks[multiple_tracks$same_lines == i,]
        print(temporary_table$name)
        
        # a repoertory to save intermediary files
        my_temp_path = paste0(my_path, i, "/")
        dir.create(my_temp_path)
        
        # 
        list_double = temporary_table$id
        for(i in 1:length(list_double))
            {
        writeLines(paste0("[out:csv(::count)];relation(",list_double[i], ");>;out count;"), 
                         paste0(my_temp_path, "query.osm"))
            
        download.file("https://overpass-api.de/api/interpreter", method = "wget",
                  destfile = paste0(my_temp_path, list_double[i], ".osm") ,
                  extra = paste0("--post-file=",
                  my_temp_path,
                  "query.osm"))    
        
        Sys.sleep(15) # I should learn understand how to do a statistical count instead of this hack ...
        }
        
    }


```

